import json
import boto3
import urllib
import csv
import codecs
import random
import string
import time
from decimal import Decimal

class DecimalEncoder(json.JSONEncoder):
    def default(self, obj):
        if isinstance(obj, Decimal):
            return str(obj)
        return json.JSONEncoder.default(self, obj)
    
def generate_code(prefix, string_length):
  letters = string.ascii_uppercase
  return prefix + ''.join(random.choice(letters) for i in range(string_length))

def hello(event, context):
    body = {
        "message": "We are team John Bons and this is the hello world",
    }

    print("I added a pretty little print here for debugging")
    print(event)

    response = {"statusCode": 200, "body": json.dumps(body)}

    return response

#Challenge 2 Starts here
#Retrieval of Products
def get_all_products(event, context):
    body = {
        "message": "I'm getting all the products",
        "input": event,
    }
    
    table_name = "products-johnbons2" # change this to your dynamodb table name
    
    dynamodb = boto3.resource('dynamodb', region_name='us-east-2')
    table = dynamodb.Table(table_name)
    
    return_body = {}
    return_body["items"] = table.scan().get('Items')
    
    return_body["status"] = "success"

    response = {"statusCode": 200, "body": json.dumps(return_body, cls=DecimalEncoder)}

    
    return response
    
def create_one_product(event, context):
    body = json.loads(event["body"], parse_float=Decimal)
    
    table_name = "products-johnbons2"
    dynamodb = boto3.resource('dynamodb', region_name='us-east-2')
    table = dynamodb.Table(table_name)
    
    table.put_item(Item=body)
    
    response = {"statusCode": 200, "body": json.dumps(body, cls=DecimalEncoder)}
    
    sqs = boto3.client('sqs', region_name='us-east-2')
    queue_url = sqs.get_queue_url(QueueName='products-queue-johnbons-sqs')['QueueUrl']
    sqs.send_message(QueueUrl=queue_url, MessageBody=json.dumps(body, cls=DecimalEncoder))

    # Log the event to CloudWatch
    log_client = boto3.client("logs", region_name="us-east-2")
    log_group_name = "/aws/lambda/product-creation-logs"
    log_stream_name = time.strftime("%Y/%m/%d")

    # Ensure log group exists
    try:
        log_client.create_log_group(logGroupName=log_group_name)
    except log_client.exceptions.ResourceAlreadyExistsException:
        pass

    # Ensure log stream exists
    try:
        log_client.create_log_stream(logGroupName=log_group_name, logStreamName=log_stream_name)
    except log_client.exceptions.ResourceAlreadyExistsException:
        pass

    # Log the product creation
    log_client.put_log_events(
        logGroupName=log_group_name,
        logStreamName=log_stream_name,
        logEvents=[{
            "timestamp": int(time.time() * 1000),
            "message": f"Product created: {body['productId']}"
        }]
    )

    return response
    
# Get One Product
def get_one_product(event, context):
    table_name = "products-johnbons2"  # Ensure this matches your actual table name
    dynamodb = boto3.resource("dynamodb", region_name="us-east-2")
    table = dynamodb.Table(table_name)

    # Debugging print to check the event received
    print("Received event:", json.dumps(event, indent=2))

    # Extract the productId from the API Gateway event
    path_params = event.get("pathParameters")
    if not path_params or "productId" not in path_params:
        return {
            "statusCode": 400,
            "body": json.dumps({"message": "Bad Request: productId is required"})
        }

    product_id = path_params["productId"]

    # Corrected Key to match DynamoDB schema
    response = table.get_item(Key={"productId": product_id})

    # Check if the product exists
    if "Item" not in response:
        return {
            "statusCode": 404,
            "body": json.dumps({"message": "Product not found"})
        }

    return {
        "statusCode": 200,
        "body": json.dumps(response["Item"], cls=DecimalEncoder)
    }

# Delete One Product
def delete_one_product(event, context):
    table_name = "products-johnbons2"  # Ensure this matches your actual table name
    dynamodb = boto3.resource("dynamodb", region_name="us-east-2")
    table = dynamodb.Table(table_name)

    # Debugging print to check the event received
    print("Received event:", json.dumps(event, indent=2))

    # Extract the productId from the API Gateway event
    path_params = event.get("pathParameters")
    if not path_params or "productId" not in path_params:
        return {
            "statusCode": 400,
            "body": json.dumps({"message": "Bad Request: productId is required"})
        }

    product_id = path_params["productId"]

    # Attempt to delete the item
    response = table.delete_item(Key={"productId": product_id})

    return {
        "statusCode": 200,
        "body": json.dumps({"message": f"Product {product_id} deleted successfully"})
    }

# Update One Product
def update_one_product(event, context):
    table_name = "products-johnbons2"  # Ensure this matches your actual table name
    dynamodb = boto3.resource("dynamodb", region_name="us-east-2")
    table = dynamodb.Table(table_name)

    # Debugging print to check the event received
    print("Received event:", json.dumps(event, indent=2))

    # Extract productId from path parameters
    path_params = event.get("pathParameters")
    if not path_params or "productId" not in path_params:
        return {
            "statusCode": 400,
            "body": json.dumps({"message": "Bad Request: productId is required"})
        }

    product_id = path_params["productId"]

    # Parse the request body for the updated attributes
    try:
        body = json.loads(event["body"], parse_float=Decimal)
    except (TypeError, json.JSONDecodeError):
        return {
            "statusCode": 400,
            "body": json.dumps({"message": "Invalid JSON body"})
        }

    # Ensure there's at least one field to update
    if not body:
        return {
            "statusCode": 400,
            "body": json.dumps({"message": "Bad Request: No update data provided"})
        }

    # Build the UpdateExpression dynamically
    update_expression = "SET " + ", ".join(f"#{k} = :{k}" for k in body.keys())
    expression_attribute_names = {f"#{k}": k for k in body.keys()}  # Escape reserved keywords
    expression_attribute_values = {f":{k}": v for k, v in body.items()}

    # Update the item in DynamoDB
    response = table.update_item(
        Key={"productId": product_id},
        UpdateExpression=update_expression,
        ExpressionAttributeNames=expression_attribute_names, 
        ExpressionAttributeValues=expression_attribute_values,
        ReturnValues="ALL_NEW"
    )

    return {
        "statusCode": 200,
        "body": json.dumps({
            "message": "Product updated successfully",
            "updatedAttributes": response.get("Attributes")
        }, cls=DecimalEncoder)
    }
    
    
# Challenge 3 Starts here
def batch_create_products(event, context):
    print("File uploaded trigger")
    print(event)
    
    print("Extract file location from event payload")
    bucket = event['Records'][0]['s3']['bucket']['name']
    key = urllib.parse.unquote_plus(event['Records'][0]['s3']['object']['key'])

    # Ensure only files from for_create/ folder are processed
    if not key.startswith("for_create/"):
        print(f"Skipping file {key} as it is not in the for_create/ folder")
        return {"statusCode": 400, "body": json.dumps({"message": "Invalid file location"})}

    localFilename = f'/tmp/{key.split("/")[-1]}'  # Extract filename only
    s3_client = boto3.client('s3', region_name='us-east-2')
    
    print("Downloading file to /tmp folder")
    s3_client.download_file(bucket, key, localFilename)
    
    print("Reading CSV file and inserting into DynamoDB...")
    
    with open(localFilename, 'r') as f:
        csv_reader = csv.DictReader(f)
        table_name = "products-johnbons2"
        dynamodb = boto3.resource('dynamodb', region_name='us-east-2')
        table = dynamodb.Table(table_name)
        
        for row in csv_reader:
            table.put_item(Item=row)
    
    print("All products have been added successfully!")
    return {"statusCode": 200, "body": json.dumps({"message": "Products added successfully"})}


#Bonus batch delete
def batch_delete_products(event, context):
    print("File uploaded trigger for deletion")
    print(event)
    
    print("Extract file location from event payload")
    bucket = event['Records'][0]['s3']['bucket']['name']
    key = urllib.parse.unquote_plus(event['Records'][0]['s3']['object']['key'])

    # Ensure only files from for_delete/ folder are processed
    if not key.startswith("for_delete/"):
        print(f"Skipping file {key} as it is not in the for_delete/ folder")
        return {"statusCode": 400, "body": json.dumps({"message": "Invalid file location"})}

    localFilename = f'/tmp/{key.split("/")[-1]}'  # Extract filename only
    s3_client = boto3.client('s3', region_name='us-east-2')
    
    print("Downloading file to /tmp folder")
    s3_client.download_file(bucket, key, localFilename)
    
    print("Reading CSV file and deleting products from DynamoDB...")

    with open(localFilename, 'r') as f:
        csv_reader = csv.reader(f)
        table_name = "products-johnbons2"
        dynamodb = boto3.resource('dynamodb', region_name='us-east-2')
        table = dynamodb.Table(table_name)

        for row in csv_reader:
            product_id = row[0]  # Assuming each row contains only one column: productId
            print(f"Deleting productId: {product_id}")

            table.delete_item(Key={"productId": product_id})

    print("All products listed in the file have been deleted!")
    return {"statusCode": 200, "body": json.dumps({"message": "Products deleted successfully"})}

#Challenge 4 starts here.
def receive_message_from_sqs(event, context):
    print("file uploaded trigger")
    print(event)
    
    fieldnames=["productId", "brand_name", "product_name", "price", "quantity"]
    
    file_randomized_prefix = generate_code("pycon_", 8)
    file_name = f'/tmp/product_created_{file_randomized_prefix}.csv'
    bucket = "products-s3bucket-johnbons-sqs"
    object_name = f'product_created_{file_randomized_prefix}.csv'
    
    
    with open(file_name, 'w') as f:
        writer = csv.DictWriter(f, fieldnames=fieldnames)
        for payload in event["Records"]:
            json_payload = json.loads(payload["body"])
            writer.writerow(json_payload)

   
    s3_client = boto3.client('s3')
    response = s3_client.upload_file(file_name, bucket, object_name)
        
    print("All done!")
    return {}